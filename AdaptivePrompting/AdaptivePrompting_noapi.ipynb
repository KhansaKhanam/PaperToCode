{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Adaptive-Prompt**, a method that selects the most informative examples (called exemplars) to guide a large language model (LLM) like GPT-4 in solving reasoning tasks. The goal is to iteratively build a set of exemplars that maximize the modelâ€™s performance on new, unseen questions by adaptively choosing which examples to add based on model uncertainty."
      ],
      "metadata": {
        "id": "aeMsmfFLT2Mv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fy7BS_OfneDh",
        "outputId": "2ccb570d-0147-4bbb-cf3a-aae803919134",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.91.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: dotenv in /usr/local/lib/python3.11/dist-packages (0.9.9)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (from dotenv) (1.1.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# INSTALLING REQUIRED LIBRARIES\n",
        "!pip install tqdm openai pandas dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "* **Datasets:** https://github.com/ad-freiburg/large-qa-datasets?tab=readme-ov-file\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dLREJCG9YfoO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PREPARING TRAINING DATA\n",
        "\n",
        "import json\n",
        "\n",
        "with open(\"/content/webquestions.examples.train.json\") as f_in:\n",
        "  d_1 = json.load(f_in)\n",
        "\n",
        "with open(\"/content/free917.train.examples.canonicalized.json\") as f1_in:\n",
        "  d_2 = json.load(f1_in)\n",
        "\n",
        "questions = []\n",
        "for i in d_1:\n",
        "  entry = {\n",
        "      \"url\" : i[\"url\"],\n",
        "      \"answers\" : i[\"targetValue\"],\n",
        "      \"question\" : i[\"utterance\"]\n",
        "  }\n",
        "  questions.append(entry[\"question\"])\n",
        "\n",
        "for i in d_2:\n",
        "  entry = {\n",
        "      \"question\" : i[\"utterance\"],\n",
        "      \"answers\" : i[\"targetFormula\"]\n",
        "  }\n",
        "  questions.append(entry[\"question\"])\n",
        "\n",
        "with open(\"/content/questions_train.json\",\"w\") as f_out:\n",
        "  json.dump(questions, f_out)"
      ],
      "metadata": {
        "id": "QBCKl2HAUZRW"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open(\"/content/questions_train.json\", \"r\") as f:\n",
        "  questions_train = json.load(f)\n",
        "\n",
        "print(questions_train[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdWOoeMJVMnY",
        "outputId": "b5cb1490-05c0-4a59-a6a6-62d62063f755"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['what is the name of justin bieber brother?', 'what character did natalie portman play in star wars?', 'what state does selena gomez?', 'what country is the grand bahama island in?', 'what kind of money to take to bahamas?', 'what character did john noble play in lord of the rings?', 'who does joakim noah play for?', 'where are the nfl redskins from?', 'where did saki live?', 'how old is sacha baron cohen?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PREPARING TESTING DATA\n",
        "\n",
        "import json\n",
        "\n",
        "with open(\"/content/webquestions.examples.test.json\") as f:\n",
        "  d_1 = json.load(f)\n",
        "\n",
        "with open(\"/content/free917.test.examples.canonicalized.json\") as f1:\n",
        "  d_2 = json.load(f1)\n",
        "\n",
        "questions = []\n",
        "for i in d_1:\n",
        "  entry = {\n",
        "      \"url\" : i[\"url\"],\n",
        "      \"answers\" : i[\"targetValue\"],\n",
        "      \"question\" : i[\"utterance\"]\n",
        "  }\n",
        "  questions.append(entry[\"question\"])\n",
        "\n",
        "for i in d_2:\n",
        "  entry = {\"\"\n",
        "      \"question\" : i[\"utterance\"],\n",
        "      \"answers\" : i[\"targetFormula\"]\n",
        "  }\n",
        "  questions.append(entry[\"question\"])\n",
        "\n",
        "with open(\"/content/questions_test.json\",\"w\") as fOut:\n",
        "  json.dump(questions, fOut)"
      ],
      "metadata": {
        "id": "RAGwsE2qiJ--"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "_pDSPHq8j0kS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = \"fill-in-the-api-key-you-get-from-open-ai\""
      ],
      "metadata": {
        "id": "VyVFwU3wkdJK"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reference 1: https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/\n",
        "client = openai.OpenAI(api_key=api_key)\n"
      ],
      "metadata": {
        "id": "VcGxAHdtbMSN"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def buildPrompt(exemplers, question):\n",
        "  prompt = \"\"\n",
        "  for ex in exemplers:\n",
        "    prompt += f\"\"\"\n",
        "    Question: {ex[\"question\"]} \\n\n",
        "    Reasoning: {ex[\"reasoning\"]} \\n\n",
        "    Answer: {ex[\"answers\"]} \\n\\n\n",
        "    \"\"\"\n",
        "  prompt += f\"Question: {question} \\nAnswer:\"\n",
        "  return prompt"
      ],
      "metadata": {
        "id": "yNXwQS-eXlAv"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def computeUncertainity(exemplers, question, l):\n",
        "  prompt = buildPrompt(exemplers, question)\n",
        "  answers = []\n",
        "  for i in range(l):\n",
        "    response = client.chat.completions.create(\n",
        "        model = \"gpt-4o\",\n",
        "        messages = [{\"role\":\"user\",\n",
        "                     \"content\":prompt}],\n",
        "        temperature = 0.7\n",
        "    )\n",
        "    answers.append(response.choices[0].message.content.strip())\n",
        "  unique_answers = list(set(answers))\n",
        "  return (len(unique_answers) / l)"
      ],
      "metadata": {
        "id": "tpsc5JnGWfwz"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def adaptivePrompting(questions, k, l):\n",
        "  exemplers = []\n",
        "  remaining_questions = questions.copy()\n",
        "  for i in range(k):\n",
        "    uncertainity = []\n",
        "    for j in tqdm(remaining_questions, desc = \"evaluating uncertainity....\"):\n",
        "      u = computeUncertainity(exemplers,j,l)\n",
        "      uncertainity.append((j,u))\n",
        "\n",
        "    ques_selected, max_u = max(uncertainity, key=lambda x: x[1])\n",
        "    print(f\"\\nSelected question (highest uncertainty = {max_u:.2f}):\\n{ques_selected['question']}\")\n",
        "    reasoning = input(f\"Please provide step-by-step reasoning for:\\n'{ques_selected['question']}'\\nReasoning: \")\n",
        "    answer = input(f\"Please provide the correct answer for:\\n'{ques_selected['question']}'\\nAnswer: \")\n",
        "    exemplers.append({\n",
        "        \"question\": ques_selected[\"question\"],\n",
        "        \"reasoning\": reasoning,\n",
        "        \"answers\": answer\n",
        "        })\n",
        "    remaining_questions.remove(ques_selected)\n",
        "  return exemplers"
      ],
      "metadata": {
        "id": "9zGMxMIpIk2v"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "The temperature parameter controls the randomness of the model's output.\n",
        "A value of 0 makes the output more deterministic (less random),\n",
        "while higher values make it more creative and varied.\n",
        "\n",
        "max_tokens: This sets the maximum number of tokens (words or sub-word\n",
        "units) that the model will generate in its response.\n",
        "'''\n",
        "\n",
        "K = 3 # No. of exemplers\n",
        "L = 5 # No. of times we run loop to determine the uncertainity\n",
        "\n",
        "train_data_path = \"/content/questions_train.json\"\n",
        "test_data_path = \"/content/questions_test.json\"\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  print(\"\"\"\n",
        "  The Power of Adaptation: \\n\\n\n",
        "  Boosting In-Context Learning through Adaptive Prompting\n",
        "  \"\"\")\n",
        "  with open(train_data_path, \"r\") as f:\n",
        "    train_data = json.load(f)\n",
        "\n",
        "  with open(test_data_path, \"r\") as f:\n",
        "    test_data = json.load(f)\n",
        "\n",
        "  exemplers = adaptivePrompting(train_data, K, L)\n",
        "  for ex in exemplers:\n",
        "    print(f\"Question: {ex['question']}\\nReasoning: {ex['reasoning']}\\nAnswer: {ex['answers']}\\n\")\n",
        "  print(\"Verifying model understanding with test set\")\n",
        "  for q in test_data:\n",
        "    prompt = buildPrompt(exemplers, q)\n",
        "    response = client.ChatCompletion.create(\n",
        "        model = \"gpt-4\",\n",
        "        messages = [{\"role\":\"user\",\n",
        "                     \"content\":prompt}],\n",
        "        temperature = 0\n",
        "    )\n",
        "    print(f\"Question: {q}\\nAnswer: {response['choices'][0]['message']['content'].strip()}\\n\")"
      ],
      "metadata": {
        "id": "7G6riV68bWEO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "outputId": "f88231c2-3108-4217-9e43-e37ccf2f124d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  The Power of Adaptation: \n",
            "\n",
            "\n",
            "  Boosting In-Context Learning through Adaptive Prompting\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "evaluating uncertainity....:   0%|          | 0/4419 [00:02<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RateLimitError",
          "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-41-39404327.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m   \u001b[0mexemplers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madaptivePrompting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexemplers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Question: {ex['question']}\\nReasoning: {ex['reasoning']}\\nAnswer: {ex['answers']}\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-40-2270904415.py\u001b[0m in \u001b[0;36madaptivePrompting\u001b[0;34m(questions, k, l)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0muncertainity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining_questions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"evaluating uncertainity....\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m       \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomputeUncertainity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexemplers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m       \u001b[0muncertainity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-39-1680667324.py\u001b[0m in \u001b[0;36mcomputeUncertainity\u001b[0;34m(exemplers, question, l)\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0manswers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     response = client.chat.completions.create(\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"gpt-4o\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         messages = [{\"role\":\"user\",\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/resources/chat/completions/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    923\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m    924\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    926\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1247\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m         )\n\u001b[0;32m-> 1249\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                 \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since there's a limit on the number of calls you can make with the free version we couldn't test the model."
      ],
      "metadata": {
        "id": "04dHeKaqudTH"
      }
    }
  ]
}